ifndef::imagesdir[:imagesdir: ../images]

[[section-solution-strategy]]
== Solution Strategy

Our approach is founded on the Retrieval Augmented Generation (RAG) methodology.

To increase the precision of LLM and improve it with specific domain vernacular without requiring supplementary training, we execute a semantic search based on the user's prompt utilizing a knowledge base.
The outcomes of these searches are then employed to augment the context. This augmented context is subsequently deployed in conjunction with the original prompt to query one of the available LLMs.

.A brief overview of RAG approach used in FlexiMind.
image::04_rag_approach.excalidraw.png[]

[cols="1,2,3"]
|===
|Quality goal|Scenario|Solution approach

|
Q-1 Privacy
|
Solution should be applicable for storing and quering sensitive data.
|
Ability to work with locally hosted LLMs, ability to run on private cloud (VPC).
Providing explicit information about guaranteed level of privacy.

|
Q-1 Privacy
|
Users belonging to different groups should not see each other information.
|
System suports multi tenancy.
Each user group has its own konwledge base.
Conversation history is stored per user.
Contexts are defined per tenant.

|
Q-2 Information tracking
|
User wants to verify the correctness of the generated text.
|
Storing meta information in semantic search index and providing links to the source information to the user.

|
Q-3 Accuracy
|
Solution should be fine tuned for requested domain knowledge.
|
Use of RAG, semantic searching and indexing. Proper prompt engineering that quarantees lack of hallucinated answers (answers must be limited to the provided knowlege).


|===